# -*- coding: utf-8 -*-
"""Bismillah ini yang terbaik.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xuQJKAbboHevyqxUD-04jQ6_DYObtENI
"""
import streamlit as st
import pandas as pd
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import numpy as np

# Function to convert string values to bps
def convert_to_bps(value):
    if 'Mb/s' in value:
        return abs(float(value.replace(' Mb/s', '')) * 1e6)
    elif 'kb/s' in value:
        return abs(float(value.replace(' kb/s', '')) * 1e3)
    elif 'b/s' in value:
        return abs(float(value.replace(' b/s', '')))
    else:
        return 0.0

# Function to denormalize predictions
def denormalize(predictions, column_name, scaler, scaled_columns):
    predictions = predictions.flatten()
    min_val = scaler.data_min_[scaled_columns.index(column_name)]
    max_val = scaler.data_max_[scaled_columns.index(column_name)]
    denorm_predictions = predictions * (max_val - min_val) + min_val
    return denorm_predictions

# Streamlit app
st.title("Prediksi Kecepatan Internet")

# CSV File Uploader
st.subheader("CSV File Uploader:")
uploaded_file = st.file_uploader("Upload CSV file:", type=['csv'])

if uploaded_file is not None:
    delimiters = (',', ';')
    df = pd.read_csv(uploaded_file, sep='[,;]', engine='python')
    df['Time'] = pd.to_datetime(df['Time'], format='%d/%m/%Y %H:%M')

    # Menampilkan beberapa baris pertama untuk memastikan data terbaca dengan benar
    st.write(df.head())

    # Mengubah nilai menjadi numerik, menghilangkan satuan seperti 'b/s', 'kb/s', 'Mb/s'
    for col in df.columns[1:]:
        df[col] = df[col].apply(convert_to_bps)

    # Menampilkan beberapa baris pertama untuk memastikan perubahan
    st.write(df.head())

    # Allow the user to select the input and output columns dynamically
    date_f = st.selectbox(label="Select Date Feature:", options=df.columns)
    input_columns = st.multiselect("Select Input Features (X):", options=[element for element in list(df.columns) if element != date_f])
    output_columns = st.multiselect("Select Output Feature (Y):", options=[element for element in list(df.columns) if element != date_f])

    if input_columns and output_columns:
        # Mengambil jam dari kolom 'Time'
        df['Hour'] = df['Time'].dt.hour

        # Mengambil data pada jam tertentu
        target_hours = [8, 11, 14]
        df_target = df[df['Hour'].isin(target_hours)]

        # Mengkonversi jam menjadi fitur numerik
        label_encoder = LabelEncoder()
        df_target['Hour_Encoded'] = label_encoder.fit_transform(df_target['Hour'])

        # Normalize the data
        scaled_columns = input_columns + output_columns
        scaler = MinMaxScaler()
        df_target[scaled_columns] = scaler.fit_transform(df_target[scaled_columns])

        # Split data into features and target
        X = df_target[['Hour_Encoded'] + input_columns]
        y = df_target[output_columns]

        # Split into training and test sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Define LSTM model architecture
        def build_lstm_model(input_shape):
            model = Sequential([
                LSTM(80, activation='relu', input_shape=input_shape, return_sequences=True),
                Dropout(0.2),
                LSTM(80, activation='relu'),
                Dropout(0.2),
                Dense(len(output_columns))
            ])
            model.compile(optimizer='adam', loss='mean_squared_error')
            return model

        model = build_lstm_model((X_train.shape[1], 1))

        # Reshape features for LSTM input
        X_train = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))

        # Train and evaluate LSTM models
        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])

        predictions = model.predict(X_test)
        denorm_predictions = denormalize(predictions, output_columns[0], scaler, scaled_columns)
        denorm_actual = denormalize(y_test.values, output_columns[0], scaler, scaled_columns)
        mse = mean_squared_error(denorm_actual, denorm_predictions)

        st.write('MSE:', mse)

        # Plot predictions vs actual values
        plt.figure(figsize=(10, 5))
        plt.plot(denorm_actual, label='Actual')
        plt.plot(denorm_predictions, label='Predicted')
        plt.title('Actual vs Predicted')
        plt.legend()
        st.pyplot(plt)
else:
    st.write("Silakan unggah file CSV.")
